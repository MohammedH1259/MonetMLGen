{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np \nimport pandas as pd \nimport os \nimport matplotlib.pyplot as plt\nimport matplotlib as mpl \nimport time\nimport functools \nimport IPython.display as display \nimport PIL.Image \n","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:48.206601Z","iopub.execute_input":"2022-06-02T17:21:48.207124Z","iopub.status.idle":"2022-06-02T17:21:48.213486Z","shell.execute_reply.started":"2022-06-02T17:21:48.207081Z","shell.execute_reply":"2022-06-02T17:21:48.212579Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TASK: **\n>Transforming an Image to look like a Monet Painting \n>Generative Adversarial Networks -","metadata":{"_kg_hide-output":true}},{"cell_type":"markdown","source":"** Code Workflow and Inital Notes **\n>Want to create this in tensorFlow -> Good Practice Problem \n\nV0.1 \n>Create a program that is able to to do basic neural style transfer following tensor flow documentation\n>This is not optimized and there is a better way of doing this similar to cyclegan which generates an image in a particular style rather than transfering the style over ","metadata":{}},{"cell_type":"markdown","source":"**GAN Notes **\n>Generative Adversarial Networks -> Two Models trained simultaneously \n>Generator (Artist Network) -> Learns to create images that look real\n>Discriminator (Critic Network) -> Learns to tell real images apart from fakes \n> More Clearly We are trying to neural style transfer referenced in Gatys et al. ","metadata":{}},{"cell_type":"markdown","source":"* Coding Notes & Structure Notes * \n>Rather than getting into direct coding define tasks that will be repeated multiple times throughout the process and convert them into functions ","metadata":{}},{"cell_type":"markdown","source":"Definition: Tensor to Image \n>Takes in a tensor and returns an image \n\nNotes:\nPIL.Image -> Python Imaging Library > Image class a\n>General Image Editing Capabilities, in this case we are using PIL.Image.fromarray - > to turn an array(our tensor turned into np.array) into an image \n\n>tensor = tensor*255 -> Our tensor will most likely be normalized due to easier processsing so we will need to unnormalize \n\n>dont know what the assert is doing exactly but it seems to be reshaping tensor to an array format for .fromarray code ","metadata":{}},{"cell_type":"code","source":"def tensor_to_image(tensor):\n    tensor = tensor*255\n    tensor = np.array(tensor, dtype = np.uint8)\n    if np.ndim(tensor>3):\n        assert tensor.shape[0] == 1\n        tensor = tensor[0]\n    return PIL.Image.fromarray(tensor)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:52.877948Z","iopub.execute_input":"2022-06-02T17:21:52.878349Z","iopub.status.idle":"2022-06-02T17:21:52.884046Z","shell.execute_reply.started":"2022-06-02T17:21:52.878306Z","shell.execute_reply":"2022-06-02T17:21:52.883214Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Definition : Load an Image from Path and limit its dimension to 512 pixels ","metadata":{}},{"cell_type":"code","source":"def load_img(path_to_img):\n    max_dim = 512\n    img = tf.io.read_file(path_to_img)\n    img = tf.image.decode_image(img, channels = 3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    \n    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n    long_dim = max(shape)\n    scale = max_dim/long_dim\n    \n    new_shape = tf.cast(shape*scale, tf.int32)\n    img = tf.image.resize(img, new_shape)\n    img = img[tf.newaxis, :]\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:52.885076Z","iopub.execute_input":"2022-06-02T17:21:52.885464Z","iopub.status.idle":"2022-06-02T17:21:52.904366Z","shell.execute_reply.started":"2022-06-02T17:21:52.885403Z","shell.execute_reply":"2022-06-02T17:21:52.903504Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Definition: Imshow -> Pretty obvious haha","metadata":{}},{"cell_type":"code","source":"def imshow(image, title = None):\n    if len(image.shape)>3:\n        image = tf.squeeze(image, axis = 0)\n    \n    plt.imshow(image)\n    if title:\n        plt.title(title)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:52.906695Z","iopub.execute_input":"2022-06-02T17:21:52.907266Z","iopub.status.idle":"2022-06-02T17:21:52.917735Z","shell.execute_reply.started":"2022-06-02T17:21:52.907230Z","shell.execute_reply":"2022-06-02T17:21:52.916671Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Code Snippet to Load Two Images \n>We will choose one from content and one from style","metadata":{}},{"cell_type":"code","source":"style_image = load_img(\"../input/gan-getting-started/monet_jpg/000c1e3bff.jpg\")\ncontent_img = load_img(\"../input/gan-getting-started/photo_jpg/00068bc07f.jpg\")\n\nplt.subplot(1,2,1)\nimshow(style_image, \"Monet Style\")\n\nplt.subplot(1,2,2)\nimshow(content_img, \"Photo to Be Converted\")","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:52.919449Z","iopub.execute_input":"2022-06-02T17:21:52.919822Z","iopub.status.idle":"2022-06-02T17:21:53.361621Z","shell.execute_reply.started":"2022-06-02T17:21:52.919788Z","shell.execute_reply":"2022-06-02T17:21:53.357760Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"vgg = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet')\n\nprint()\nfor layer in vgg.layers:\n    print(layer.name)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:53.362853Z","iopub.execute_input":"2022-06-02T17:21:53.363382Z","iopub.status.idle":"2022-06-02T17:21:54.078102Z","shell.execute_reply.started":"2022-06-02T17:21:53.363345Z","shell.execute_reply":"2022-06-02T17:21:54.076453Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"The above code represents a already created network from tensor flow, CNN for image classification, we removed the classification layer and will now choose intermediate layers to represent style and content of the image ","metadata":{}},{"cell_type":"code","source":"content_layers = ['block5_conv2']\n\nstyle_layers = ['block1_conv1',\n                'block2_conv1',\n                'block3_conv1',\n                'block4_conv1',\n                'block5_conv1']","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:21:54.079354Z","iopub.execute_input":"2022-06-02T17:21:54.079802Z","iopub.status.idle":"2022-06-02T17:21:54.085859Z","shell.execute_reply.started":"2022-06-02T17:21:54.079754Z","shell.execute_reply":"2022-06-02T17:21:54.084474Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Definition: Creating a Pretrained Model ","metadata":{}},{"cell_type":"code","source":"def vgg_layers(layer_names):\n    vgg = tf.keras.applications.VGG19(include_top = False, weights = 'imagenet')\n    vgg.trainable = False\n    \n    outputs = [vgg.get_layer(name).output for name in layer_names]\n    model = tf.keras.Model([vgg.input], outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:23:02.413069Z","iopub.execute_input":"2022-06-02T17:23:02.413602Z","iopub.status.idle":"2022-06-02T17:23:02.420971Z","shell.execute_reply.started":"2022-06-02T17:23:02.413555Z","shell.execute_reply":"2022-06-02T17:23:02.419912Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"style_extractor = vgg_layers(style_layers)\nstyle_outputs = style_extractor(style_image*255)\n\nfor name, output in zip(style_layers, style_outputs):\n    print(name)\n    print(\" Shape: \", output.numpy().shape)\n    print(\" min: \", output.numpy().min)\n    print(\"max: \", output.numpy().max)\n    print(\"mean: \", ouput.numpy().mean)\n    print()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:24:36.352993Z","iopub.execute_input":"2022-06-02T17:24:36.353536Z","iopub.status.idle":"2022-06-02T17:24:38.805498Z","shell.execute_reply.started":"2022-06-02T17:24:36.353488Z","shell.execute_reply":"2022-06-02T17:24:38.804066Z"},"trusted":true},"execution_count":35,"outputs":[]}]}